<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Continuous Wrist Control on the Hannes Prosthesis: a Vision-based Shared Autonomy Framework</title>
  <link rel="icon" type="image/x-icon" href="static/images/hsp-logo.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Continuous Wrist Control on the Hannes Prosthesis: a Vision-based Shared Autonomy Framework</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://federicovasile1.github.io/website/" target="_blank">Federico Vasile</a>,
              </span>
              <span class="author-block">
                <a href="https://www.iit.it/it/people-details/-/people/elisa-maiettini" target="_blank">Elisa Maiettini</a>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.it/citations?user=8EKDQjcAAAAJ&hl=it" target="_blank">Giulia Pasquale</a>,
              </span>
              <span class="author-block">
                <a href="https://www.iit.it/it/people-details/-/people/nicolo-boccardo" target="_blank">NicolÃ² Boccardo</a>,
              </span>
              <span class="author-block">
                <a href="https://hsp.iit.it/people-details/-/people/lorenzo-natale" target="_blank">Lorenzo Natale</a>
              </span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Italian Institute of Technology, University of Genoa<br><b>ICRA 2025</b></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links"></div>

                        <!-- ArXiv abstract Link -->
                        <span class="link-block">
                          <a href="https://arxiv.org/abs/2502.17265" target="_blank"
                          class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">
                            <i class="ai ai-arxiv"></i>
                          </span>
                          <span>arXiv</span>
                        </a>
                      </span>

                      <!-- Github link -->
                      <span class="link-block">
                        <a href="https://github.com/hsp-iit/hannes-wrist-control" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fab fa-github"></i>
                        </span>
                        <span>Code</span>
                      </a>
                    </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/teaser-video.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        TL;DR: We propose a shared autonomy framework for continuos wrist control, 
        <br>aiming to improve the grasping motion of prosthetic hands 
        <br>and reduce the cognitive load on the user.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Most control techniques for prosthetic grasping focus on dexterous fingers control, but overlook the wrist motion. This forces the user to perform compensatory movements with the elbow, shoulder and hip to adapt the wrist for grasping. 
We propose a computer vision-based system that leverages the collaboration between the user and an automatic system in a shared autonomy framework, to perform continuous control of the wrist degrees of freedom in a prosthetic arm, promoting a more natural approach-to-grasp motion. Our pipeline allows to seamlessly control the prosthetic wrist to follow the target object and finally orient it for grasping according to the user intent. We assess the effectiveness of each system component through quantitative analysis and finally deploy our method on the Hannes prosthetic arm.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- News amputees-->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered has-text-danger">NEWSðŸš€</h2>
      <div class="content">
        <p class="has-text-centered">
          <b>We are validating our system in clinical trials to assess <i>user satisfaction</i>, <i>cognitive load</i>, and <i>compensatory movements</i>. <br>Stay tuned for more results!</b>
        </p>
      </div>

      <div class="columns is-centered">
        <div class="column">
          <video class="scaled-video" poster="" id="test1" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/test1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="column">
          <video class="scaled-video"  poster="" id="test2" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/test2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="column">
          <video class="scaled-video" poster="" id="test3" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/test3.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      
    </div>
  </div>
</section>
<!-- End News Amputees-->


<!-- Visual Servoing Demonstration-->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Visual Servoing Demonstration</h2>
      <div class="content">
        <p class="has-text-centered">
          We propose a visual servoing control to continuously orient the wrist towards the target object, 
          <br>promoting a more natural approach-to-grasp motion.
        </p>
      </div>

      <div id="results-carousel" class="carousel results-carousel">

        <div class="item item-mustard">
          <video poster="" id="mustard" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/vservo-mustard.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mug">
          <video poster="" id="mug" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/vservo-mug.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-pitcher">
          <video poster="" id="pitcher" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/vservo-pitcher.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chipscan">
          <video poster="" id="chipscan" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/vservo-chipscan.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
        <p class="has-text-centered">
          (hover to play until the end)
        </p>
    </div>
  </div>
</section>
<!-- End Visual Servoing Demonstration-->



<!-- Object parts segmentation -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Object Parts Segmentation</h2>
      <p class="has-text-centered">
        Our DINOv2Det model segments the object parts into top and side grasps.
      </p>
      <div class="hero-body">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <source src="static/videos/segmentation.mp4"
          type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>
<!-- End Object parts segmentation -->


<!-- Framework Overview-->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Framework Overview</h2>
      <p class="has-text-centered">
        We propose a shared autonomy framework to closely mimic the kinematics of a reach-to-grasp task. During the Transport phase, we segment the object into parts using our DINOv2Det model and use a custom visual servoing (pp-IBVS) to orient the wrist towards the target object. Then, the user triggers the Rotation phase via EMG signals, and the wrist is engaged into Top or Side grasp based on the predicted object part. Finally, the user controls the closing of the fingers to grasp the object.
      </p>
      <div class="hero-body">
        <div style="text-align: center;">
          <img src="static/images/framework.jpg" alt="Framework Overview" height="100%">
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Framework Overview-->


<!-- EMG baseline -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">EMG Baseline</h2>
      <p class="has-text-centered">
        We provide a qualitative comparison with a baseline using electromyography (EMG) signals for the control of the wrist and fingers. It adopts the Sequential Switching and Control paradigm, where the user drives each joint sequentially. 
        <br>This method hinders a natural approach-to-grasp motion and increases the cognitive load on the user.
      </p>
      <div class="hero-body">
        <div style="text-align: center;">
          <video poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="static/videos/emg-baseline.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End EMG baseline -->



<!-- Visual servoing analysis-->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Visual Servoing Analysis</h2>
      <p class="has-text-centered">
        We show two experiments to highlight the differences between the standard Image Based Visual Servoing (s-IBVS) 
        <br>and our proportional and partitioned Visual Servoing (pp-IBVS). 
        <br> See Sec. V.B in the paper for more details.
      </p>
      <div class="hero-body">
        <div style="text-align: center;">
          <video poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="static/videos/vservo-analysis.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Visual Servoing Analysis-->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{vasile2025continuous,
  title={Continuous Wrist Control on the Hannes Prosthesis: a Vision-based Shared Autonomy Framework},
  author={Vasile, Federico and Maiettini, Elisa and Pasquale, Giulia and Boccardo, Nicol{\`o} and Natale, Lorenzo},
  booktitle={2025 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={},
  year={2025},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
